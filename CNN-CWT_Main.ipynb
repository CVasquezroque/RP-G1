{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x2857fe09750>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import cv2\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pywt\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from functools import partial\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, make_scorer\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import EpochScoring, Initializer, LRScheduler, TensorBoard\n",
    "from skorch.dataset import Dataset\n",
    "from skorch.helper import predefined_split\n",
    "from torch.backends import cudnn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 7)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pooling1 = nn.MaxPool2d(5)\n",
    "        self.pooling2 = nn.MaxPool2d(3)\n",
    "        self.pooling3 = nn.AdaptiveMaxPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(68, 32)\n",
    "        self.fc2 = nn.Linear(32, 4)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = F.relu(self.bn1(self.conv1(x1)))  # (16 x 94 x 94)\n",
    "        x1 = self.pooling1(x1)  # (16 x 18 x 18)\n",
    "        x1 = F.relu(self.bn2(self.conv2(x1)))  # (32 x 16 x 16)\n",
    "        x1 = self.pooling2(x1)  # (32 x 5 x 5)\n",
    "        x1 = F.relu(self.bn3(self.conv3(x1)))  # (64 x 3 x 3)\n",
    "        x1 = self.pooling3(x1)  # (64 x 1 x 1)\n",
    "        x1 = x1.view((-1, 64))  # (64,)\n",
    "        x = torch.cat((x1, x2), dim=1)  # (68,)\n",
    "        x = F.relu(self.fc1(x))  # (32,)\n",
    "        x = self.fc2(x)  # (4,)\n",
    "        return x\n",
    "\n",
    "\n",
    "def worker(data, wavelet, scales, sampling_period):\n",
    "    # heartbeat segmentation interval\n",
    "    before, after = 90, 110\n",
    "\n",
    "    coeffs, frequencies = pywt.cwt(data[\"signal\"], scales, wavelet, sampling_period)\n",
    "    r_peaks, categories = data[\"r_peaks\"], data[\"categories\"]\n",
    "\n",
    "    # for remove inter-patient variation\n",
    "    avg_rri = np.mean(np.diff(r_peaks))\n",
    "\n",
    "    x1, x2, y, groups = [], [], [], []\n",
    "    for i in range(len(r_peaks)):\n",
    "        if i == 0 or i == len(r_peaks) - 1:\n",
    "            continue\n",
    "\n",
    "        if categories[i] == 4:  # remove AAMI Q class\n",
    "            continue\n",
    "\n",
    "        # cv2.resize is used to sampling the scalogram to (100 x100)\n",
    "        x1.append(cv2.resize(coeffs[:, r_peaks[i] - before: r_peaks[i] + after], (100, 100)))\n",
    "        x2.append([\n",
    "            r_peaks[i] - r_peaks[i - 1] - avg_rri,  # previous RR Interval\n",
    "            r_peaks[i + 1] - r_peaks[i] - avg_rri,  # post RR Interval\n",
    "            (r_peaks[i] - r_peaks[i - 1]) / (r_peaks[i + 1] - r_peaks[i]),  # ratio RR Interval\n",
    "            np.mean(np.diff(r_peaks[np.maximum(i - 10, 0):i + 1])) - avg_rri  # local RR Interval\n",
    "        ])\n",
    "        y.append(categories[i])\n",
    "        groups.append(data[\"record\"])\n",
    "\n",
    "    return x1, x2, y, groups\n",
    "\n",
    "\n",
    "def load_data(wavelet, scales, sampling_rate, filename=\"./dataset/mitdb.pkl\"):\n",
    "    import pickle\n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "    with open(filename, \"rb\") as f:\n",
    "        train_data, test_data = pickle.load(f)\n",
    "\n",
    "    cpus = 22 if joblib.cpu_count() > 22 else joblib.cpu_count() - 1  # for multi-process\n",
    "\n",
    "    # for training\n",
    "    x1_train, x2_train, y_train, groups_train = [], [], [], []\n",
    "    # with ProcessPoolExecutor(max_workers=cpus) as executor:\n",
    "\n",
    "    for data in train_data:\n",
    "        x1, x2, y, groups = worker(data, wavelet=wavelet, scales=scales, sampling_period=1. / sampling_rate)\n",
    "        x1_train.append(x1)\n",
    "        x2_train.append(x2)\n",
    "        y_train.append(y)\n",
    "        groups_train.append(groups)\n",
    "\n",
    "    x1_train = np.expand_dims(np.concatenate(x1_train, axis=0), axis=1).astype(np.float32)\n",
    "    x2_train = np.concatenate(x2_train, axis=0).astype(np.float32)\n",
    "    y_train = np.concatenate(y_train, axis=0).astype(np.int64)\n",
    "    groups_train = np.concatenate(groups_train, axis=0)\n",
    "\n",
    "    # for test\n",
    "    x1_test, x2_test, y_test, groups_test = [], [], [], []\n",
    "    # with ProcessPoolExecutor(max_workers=cpus) as executor:\n",
    "\n",
    "    for data in test_data:\n",
    "        x1, x2, y, groups = worker(data, wavelet=wavelet, scales=scales, sampling_period=1. / sampling_rate)\n",
    "        x1_test.append(x1)\n",
    "        x2_test.append(x2)\n",
    "        y_test.append(y)\n",
    "        groups_test.append(groups)\n",
    "\n",
    "    x1_test = np.expand_dims(np.concatenate(x1_test, axis=0), axis=1).astype(np.float32)\n",
    "    x2_test = np.concatenate(x2_test, axis=0).astype(np.float32)\n",
    "    y_test = np.concatenate(y_test, axis=0).astype(np.int64)\n",
    "    groups_test = np.concatenate(groups_test, axis=0)\n",
    "\n",
    "    # normalization\n",
    "    scaler = RobustScaler()\n",
    "    x2_train = scaler.fit_transform(x2_train)\n",
    "    x2_test = scaler.transform(x2_test)\n",
    "\n",
    "    return (x1_train, x2_train, y_train, groups_train), (x1_test, x2_test, y_test, groups_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oks\n",
      "Data loaded successfully!\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-2ace68f6ce0f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     34\u001B[0m     \u001B[0moptimizer__weight_decay\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     35\u001B[0m )\n\u001B[1;32m---> 36\u001B[1;33m \u001B[0mnet\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m\"x1\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mx1_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"x2\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mx2_train\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     37\u001B[0m \u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnet\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m\"x1\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mx1_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"x2\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mx2_test\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\aldo tecse\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\skorch\\classifier.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m    140\u001B[0m         \u001B[1;31m# this is actually a pylint bug:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    141\u001B[0m         \u001B[1;31m# https://github.com/PyCQA/pylint/issues/1085\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 142\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mNeuralNetClassifier\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    143\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    144\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mpredict_proba\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\aldo tecse\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\skorch\\net.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m    913\u001B[0m         \"\"\"\n\u001B[0;32m    914\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwarm_start\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minitialized_\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 915\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minitialize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    916\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    917\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpartial_fit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\aldo tecse\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\skorch\\net.py\u001B[0m in \u001B[0;36minitialize\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    598\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minitialize_callbacks\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    599\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minitialize_criterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 600\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minitialize_module\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    601\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minitialize_optimizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    602\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minitialize_history\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\aldo tecse\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\skorch\\net.py\u001B[0m in \u001B[0;36minitialize_module\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    528\u001B[0m             \u001B[0mmodule\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    529\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 530\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodule_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mto_device\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodule\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    531\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    532\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\aldo tecse\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\skorch\\utils.py\u001B[0m in \u001B[0;36mto_device\u001B[1;34m(X, device)\u001B[0m\n\u001B[0;32m    166\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtuple\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mPackedSequence\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    167\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mto_device\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 168\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    169\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    170\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\aldo tecse\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36mto\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n",
      "\u001B[1;32mc:\\users\\aldo tecse\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n",
      "\u001B[1;32mc:\\users\\aldo tecse\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n",
      "\u001B[1;32mc:\\users\\aldo tecse\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36mconvert\u001B[1;34m(t)\u001B[0m\n",
      "\u001B[1;32mc:\\users\\aldo tecse\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\cuda\\__init__.py\u001B[0m in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "sampling_rate = 360\n",
    "\n",
    "wavelet = \"mexh\"  # mexh, morl, gaus8, gaus4\n",
    "scales = pywt.central_frequency(wavelet) * sampling_rate / np.arange(1, 101, 1)\n",
    "\n",
    "print(\"oks\")\n",
    "\n",
    "(x1_train, x2_train, y_train, groups_train), (x1_test, x2_test, y_test, groups_test) = load_data(\n",
    "    wavelet=wavelet, scales=scales, sampling_rate=sampling_rate)\n",
    "print(\"Data loaded successfully!\")\n",
    "\n",
    "log_dir = \"./logs/{}\".format(wavelet)\n",
    "shutil.rmtree(log_dir, ignore_errors=True)\n",
    "\n",
    "callbacks = [\n",
    "    Initializer(\"[conv|fc]*.weight\", fn=torch.nn.init.kaiming_normal_),\n",
    "    Initializer(\"[conv|fc]*.bias\", fn=partial(torch.nn.init.constant_, val=0.0)),\n",
    "    LRScheduler(policy=StepLR, step_size=5, gamma=0.1),\n",
    "    EpochScoring(scoring=make_scorer(f1_score, average=\"macro\"), lower_is_better=False, name=\"valid_f1\"),\n",
    "    TensorBoard(SummaryWriter(log_dir))\n",
    "]\n",
    "net = NeuralNetClassifier(  # skorch is extensive package of pytorch for compatible with scikit-learn\n",
    "    MyModule,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    lr=0.001,\n",
    "    max_epochs=30,\n",
    "    batch_size=1024,\n",
    "    train_split=predefined_split(Dataset({\"x1\": x1_test, \"x2\": x2_test}, y_test)),\n",
    "    verbose=1,\n",
    "    device=\"cuda\",\n",
    "    callbacks=callbacks,\n",
    "    iterator_train__shuffle=True,\n",
    "    optimizer__weight_decay=0,\n",
    ")\n",
    "net.fit({\"x1\": x1_train, \"x2\": x2_train}, y_train)\n",
    "y_true, y_pred = y_test, net.predict({\"x1\": x1_test, \"x2\": x2_test})\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "#net.save_params(f_params=\"./models/model_{}.pkl\".format(wavelet))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}